{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "574f42b4",
   "metadata": {},
   "source": [
    "### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11d429c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16b05b",
   "metadata": {},
   "source": [
    "### Importing dataset and splitting into features and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf8f9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"Data.csv\")\n",
    "x=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d279c",
   "metadata": {},
   "source": [
    "### Splitting into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b933dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y,random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb0f5d",
   "metadata": {},
   "source": [
    "### THESE FIRST 3 CODE BLOCKS ABOVE ARE USED BY ALL MODELS ASIDES THE SVR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e542ccc",
   "metadata": {},
   "source": [
    " ###   MULTIPLE LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f90488a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[431.43 431.23]\n",
      " [458.56 460.01]\n",
      " [462.75 461.14]\n",
      " ...\n",
      " [469.52 473.26]\n",
      " [442.42 438.  ]\n",
      " [461.88 463.28]]\n"
     ]
    }
   ],
   "source": [
    "# training the multiple linear regression on the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "# predicting the test set result\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Putting the predicted and test values side by side to visually compare \n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "# Evaluating performance\n",
    "from sklearn.metrics import r2_score\n",
    "mulitiple_linear_regression_score=r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5101c55",
   "metadata": {},
   "source": [
    "### POLYNOMIAL REGRESION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59c923d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[433.94 431.23]\n",
      " [457.9  460.01]\n",
      " [460.52 461.14]\n",
      " ...\n",
      " [469.53 473.26]\n",
      " [438.27 438.  ]\n",
      " [461.66 463.28]]\n"
     ]
    }
   ],
   "source": [
    "# training the multiple linear regression on the training data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor=LinearRegression()\n",
    "\n",
    "# importing the tool to help create power features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg=PolynomialFeatures(degree=4)\n",
    "x_poly=poly_reg.fit_transform(x_train)\n",
    "\n",
    "regressor_2=LinearRegression()\n",
    "regressor_2.fit(x_poly,y_train)\n",
    "\n",
    "\n",
    "# predicting the test set result\n",
    "y_pred=regressor_2.predict(poly_reg.transform(x_test))\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Putting the predicted and test values side by side to visually compare \n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "# Evaluating performance\n",
    "from sklearn.metrics import r2_score\n",
    "polynomial_regression_score=r2_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aadd73",
   "metadata": {},
   "source": [
    "### DECISION TREE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf26dd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[431.28 431.23]\n",
      " [459.59 460.01]\n",
      " [460.06 461.14]\n",
      " ...\n",
      " [471.46 473.26]\n",
      " [437.76 438.  ]\n",
      " [462.74 463.28]]\n"
     ]
    }
   ],
   "source": [
    "# training the Decision tree regression model on the training data\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor=DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "# predicting the test set result\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Putting the predicted and test values side by side to visually compare \n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "# Evaluating performance\n",
    "from sklearn.metrics import r2_score\n",
    "DecisionTreeRegressor_score=r2_score(y_test,y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b611ff",
   "metadata": {},
   "source": [
    "### RANDOM FOREST REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "311197ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[434.05 431.23]\n",
      " [458.79 460.01]\n",
      " [463.02 461.14]\n",
      " ...\n",
      " [469.48 473.26]\n",
      " [439.57 438.  ]\n",
      " [460.38 463.28]]\n"
     ]
    }
   ],
   "source": [
    "# training the random forest regression model on the training data\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# we decide to use 10 trees in our model hence n_estimators=10\n",
    "\n",
    "regressor=RandomForestRegressor(n_estimators=10,random_state=0)\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "# predicting the test set result\n",
    "y_pred=regressor.predict(x_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Putting the predicted and test values side by side to visually compare \n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "# Evaluating performance\n",
    "from sklearn.metrics import r2_score\n",
    "RandomForestRegressor_score=r2_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8ffc1",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92d79bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sotom\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[434.05 431.23]\n",
      " [457.94 460.01]\n",
      " [461.03 461.14]\n",
      " ...\n",
      " [470.6  473.26]\n",
      " [439.42 438.  ]\n",
      " [460.92 463.28]]\n"
     ]
    }
   ],
   "source": [
    "# I had to put the SVR model last and just repeat a few codes in this box.\n",
    "# SVR just requires a little extra \n",
    "\n",
    "dataset=pd.read_csv(\"Data.csv\")\n",
    "x=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,-1].values\n",
    "\n",
    "# we perform feature scaling for support vector regression so we have to reshape y since the standard scalar class to be \n",
    "# used for feature scaling expects a 2d array as input\n",
    "\n",
    "y = y.reshape(len(y),1)\n",
    "\n",
    "#  splitting into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y,random_state=0, test_size=0.2)\n",
    "\n",
    "# feature scaling. Note: Feature scaling is done after splitting the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x=StandardScaler()\n",
    "sc_y=StandardScaler()\n",
    "\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "y_train=sc_y.fit_transform(y_train)\n",
    "\n",
    "# training the svr model on the whole dataset\n",
    "from sklearn.svm import SVR\n",
    "regressor=SVR(kernel='rbf')\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "# we use inverse transform method to give us sth similar to y_test since y_test was never transformed\n",
    "y_pred = sc_y.inverse_transform([regressor.predict(sc_x.transform(x_test))])\n",
    "\n",
    "# this line below helps us switch our rows and columns because the shape of y_pred above was (1,1914) and we want to resemble\n",
    "# y_test\n",
    "\n",
    "y_pred=y_pred.transpose()\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Putting the predicted and test values side by side to visually compare \n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "# Evaluating performance\n",
    "from sklearn.metrics import r2_score\n",
    "support_vector_regression_score=r2_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c991179",
   "metadata": {},
   "source": [
    "### VISUALIZING THE RESULTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c33d4608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       MODEL     SCORE\n",
      "0        Multiple Regression  0.932532\n",
      "1      Polynomial regression  0.945819\n",
      "2              Decision tree  0.922906\n",
      "3              Random forest  0.961591\n",
      "4  Support vector regression  0.948078\n",
      "\n",
      "Maximum_Score =  0.9615908334363876\n"
     ]
    }
   ],
   "source": [
    "data={'MODEL':['Multiple Regression','Polynomial regression', 'Decision tree', 'Random forest', 'Support vector regression'],\n",
    "      'SCORE':[mulitiple_linear_regression_score,polynomial_regression_score,DecisionTreeRegressor_score,RandomForestRegressor_score,\n",
    "              support_vector_regression_score]}\n",
    "result=pd.DataFrame(data=data)\n",
    "print(result)\n",
    "print()\n",
    "print('Maximum_Score = ',result['SCORE'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c5fb1e",
   "metadata": {},
   "source": [
    "### COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e472f0",
   "metadata": {},
   "source": [
    "## so you should know that regression models consist of two parameters,\n",
    "1. The parameters that are learnt (the coefficients)\n",
    "2. The hyparameters. So far for the models above, we have used the default value of this parameters and we havent searched for their \n",
    "optimal value so that the models reaches even higher performance\n",
    "3. From the results above, we can see that the Random forest regression model performs best on this dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edcf5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
